---
title: TidalCycles BoF 2019
permalink: wiki/TidalCycles_BoF_2019/
layout: wiki
---

At [ICLC 2019](https://iclc.livecodenetwork.org/2019/), we'll have a
"Birds of a Feather" workshop. We'll chat about the state of TidalCycles
and have some talks/demos.

To take place from 16:00-18:00, 17th January, 2019.

# People

If you're joining the workshop, please edit this section and add your
name and (optionally) what you'd like to get out of the workshop. Note
that you'll also need to register (free of charge) for ICLC itself here:
<https://www.medialab-prado.es/en/activities/iclc-2019-4-international-conference-live-coding>.

-   [Alex](http://slab.org/) - meet people, share ideas about growing
    and diversifying the community, and find out what others are doing
    with Tidal, maybe jam a bit
-   [Matthew](https://matthewtift.com/) - meet people, discuss
    strategies for how/why to grow the community, and I'd be happy to
    talk about my latest research
-   Nikolai - meet people, discuss the music situation in general, and
    speculate on future developements
-   Diego Dorado - meet people, share ideas about how to get the public
    involved into the livecoding performance
-   [montoyamoraga](http://montoyamoraga.io/) - meet people, jam,
    discuss live coding, have fun yay
-   [Malitzin](http://malitzincortes.net/) - meet people, hear about
    colleagues' research, share music and ways to visualize and tell
    stories through rhythmic patterns, and jam ... oh, yes!

<!-- -->

-   Please add yourself here !

To add to the above, create an account here:
<https://userbase.tidalcycles.org/index.php?title=Special:CreateAccount&returnto=TidalCycles+BoF+2019>
You'll then be able to click 'edit'.

# Talks

## Malitzin Cortes and Iván Abreu - Live Cinema Coding

Talk about the use of potential in the creation of musical patterns with
Tidal Cycles as a semantic control system for nonlinear cinema and sound
experimentation. We will talk about the practice of live cinema and
expanded cinema understood as "live cinema coding" and the opportunities
that we find when reviewing this performative expression. We will also
expose the exploration of sound with Tidal in experimental music: "take
the pattern to the limit and break it", we will reflect on the
prejudices of academia and sound art on the flexibility to model complex
sound concepts in this tool. We will show the tools we have developed to
respond to these concerns. Movabletype, a class developed in Java to
show the code in an expressive and honest way with the algorithm that
the coder executes and the Live Cinema coding engine for Tidal.

## [Alex McLean](/wiki/User%3AYaxu "wikilink") - TidalCycles v1.0.0

Tidal has been around in some form for over a decade, and has grown into
a healthy+active community over the past five years, but hasn’t really
been released yet, apart from in compile-your-own kit form, and
installers which can work well but not in all cases.

Over the past few months I've been caught in a wave of development,
reconsidering and rewriting internals, and fixing some long-standing
issues. The code (and to some extent, documentation) is now in better
shape. This has been powered on by coffee donations (thanks!), but if
we're to be a free/open source community, we should think about how to
deal with such donations fairly.

I’ll outline where tidal 1.0.0 is, some thoughts about the next tidal
bore wave of development, raise some cultural and procedural issues and
then we can have some discussion on how to take things forward.

## Alexandra Cárdenas - \#chooseuncertainty

The act of composing as seen through the lens of western classical
tradition has been mostly a matter of control. We'll revise some of
academic techniques of music composition and their relationship with
control. How can generative music help us rethink control? How does live
coding alter our perception of control? We'll talk about music and
uncertainty through the lens of TidalCycles.

## Diego Dorado - Live-emojing

Talk or brief demo about livecoding with emojis, to make the public part
of the session by sending emoji-patterns through facebook or telegram.
The idea behing this experiment is to spread the livecoding practice by
encouraging people to try out simple examples in collaboration with
others. Also interesting to talk about is: what other data could we
gather live to further engage the livecoding experience? (face
recognition, color tracking, arcade controls in the room, AR in the
room, what else?)

# More ideas

Please write here if you have more ideas for what we can do.

## Withdrawn talks

Sadly these fine people can't make it to ICLC to give their
presentations, but they're kept here for posterity (next time!)

### Withdrawn: Rodrigo Velasco - Afro-latin SpLaSh.

*A talk around odd collaborations with singers, drawers and thinkers
around Montréal and Mexico City, audio-reactive visuals and electronic
literature through 'ese2', an interface to live code the behaviour of
letters and shapes in Processing through TidalCycles. Besides I'll share
some explorations between Hydra and TidalCycles, synaesthetic
experiences and afro-latin percussion by exploring algo-rhythmic
patterns such as tumbao, dembow and montuno.*

### Withdrawn: Nikolai Polikurov - Fast Structures and Hardware Drives

*Some examples on how a systematic analysis of music structures could
provide a relatively safe space for experimenting ideas in Tidal.
Constraints and automations could be embedded in the patterns with few
lines of code. Patterns are everywhere, permitting a new way of
controlling hardware modulations, way more interesting and musically
tight than regular LFOs. Add a little bit of former, a bit of latter and
an instant digital love is guaranteed.*
